{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "train= pd.read_csv('C:/Users/Ajay/Desktop/Leaf Classification/train.csv')\n",
    "test = pd.read_csv('C:/Users/Ajay/Desktop/Leaf Classification/test.csv')\n",
    "#x_be= dataset.iloc[:,:-1].values\n",
    "#y_be = dataset.iloc[:,2:192].values\n",
    "#Standardizing the dataset by scaling the features to unit variance and removing the mean\n",
    "#sk_x_be = StandardScaler()\n",
    "#x_be = sk_x_be.fit_transform(x_be)\n",
    "\n",
    "\n",
    "\n",
    "label_init=LabelEncoder().fit(train.species) \n",
    "labels = label_init.transform(train.species)           # encode species strings\n",
    "classes = list(label_init.classes_)                    # save column names for submission\n",
    "test_ids = test.id                             # save test ids for submission\n",
    "  \n",
    "train = train.drop(['species', 'id'], axis=1)  \n",
    "test = test.drop(['id'], axis=1)\n",
    "\n",
    "labelsplit = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n",
    "\n",
    "    \n",
    "for tr_i, te_i in labelsplit:\n",
    "    x_train, x_test = train.values[tr_i], train.values[te_i]\n",
    "    y_train, y_test = labels[tr_i], labels[te_i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifierlr = LogisticRegression(solver = 'newton-cg',penalty='l2',multi_class='ovr',C=1, max_iter= 1000, random_state = 0)\n",
    "Classifierlr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6616161616161617"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction and Accuracy for Logistic Regression model on test dataset\n",
    "y_predlr = Classifierlr.predict(x_test) \n",
    "accuracy_score(y_test, y_predlr)\n",
    "\n",
    "#Prediction and Accuracy for Logistic Regression model on training dataset\n",
    "y_predtr = Classifierlr.predict(x_train)\n",
    "accuracy_score(y_train, y_predtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.5844014373426138\n",
      "recall: 0.5909090909090909\n",
      "fscore: 0.5462182392006953\n",
      "support: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_test, y_predlr, average = 'macro')\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.6693602693602694\n",
      "recall: 0.6414141414141414\n",
      "fscore: 0.6216209716209716\n",
      "support: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#DECISION TREE CLASSIFICATION MODEL\n",
    "#Implementing Decision Tree model\n",
    "Classifierdt = DecisionTreeClassifier()\n",
    "Classifierdt.fit(x_train, y_train)\n",
    "\n",
    "#Prediction and Accuracy for Decision Tree model using test dataset\n",
    "y_preddt = Classifierdt.predict(x_test)\n",
    "accuracy_score(y_test, y_preddt)\n",
    "\n",
    "#Prediction and Accuracy for Decision Tree model using training dataset\n",
    "y_preddtt = Classifierdt.predict(x_train)\n",
    "accuracy_score(y_train, y_preddtt)\n",
    "\n",
    "#Evaluation metrics for Decision Tree model\n",
    "precision, recall, fscore, support = score(y_test, y_preddt,average = 'macro')\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "#Confusion matrix for Decision Tree model\n",
    "cmdt = confusion_matrix(y_test, y_preddt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8190235690235691\n",
      "recall: 0.8232323232323232\n",
      "fscore: 0.801010101010101\n",
      "support: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SUPPORT VECTOR MACHINES MODEL (SVM\n",
    "\"\"\"\n",
    "#Implementing SVM model\n",
    "Classifiersvm = SVC(C= 1, gamma= 0.05, max_iter =1000, kernel='rbf', random_state = 1 )\n",
    "Classifiersvm.fit(x_train, y_train)\n",
    "\n",
    "#Grid Search for parameters for SVM model\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = ({'kernel':['linear'], 'C':[1,2,3,4,5,6,10,100,1000]}, {'kernel':['rbf'],'C':[1,2,3,4,5,6,7,8,9,11,12,13,14,15,10,100],'gamma':[0.04,0.05,0.06,0.07,0.03,0.02,0.01,0.6,1,2]})\n",
    "gridsearch = GridSearchCV( estimator = Classifiersvm, param_grid = parameters, scoring = 'accuracy', cv = 10)\n",
    "gridsearch = gridsearch.fit(x_train, y_train)\n",
    "bestacc = gridsearch.best_score_\n",
    "bestpara = gridsearch.best_params_\n",
    "\"\"\"\n",
    "\n",
    "#Prediction and Accuracy for SVM model using test dataset \n",
    "y_predsv = Classifiersvm.predict(x_test)\n",
    "accuracy_score(y_test, y_predsv)\n",
    "\n",
    "#Prediction and Accuracy for SVM model using training dataset\n",
    "y_predsvt = Classifiersvm.predict(x_train)\n",
    "accuracy_score(y_train, y_predsvt)\n",
    "\n",
    "#Evaluation metrics for SVM model\n",
    "precision, recall, fscore, support = score(y_test, y_predsv,average = 'macro')\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "#Confusion Matrix for SVM model\n",
    "cmsvm = confusion_matrix(y_test, y_predsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.6222309676855131\n",
      "recall: 0.5707070707070707\n",
      "fscore: 0.5476165809499143\n",
      "support: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NAIVE BAYES MODEL\n",
    "\"\"\"\n",
    "#Implementing Naive Bayes model\n",
    "Classifiernb = GaussianNB()\n",
    "Classifiernb.fit(x_train, y_train)\n",
    "\n",
    "#Prediction and Accuracy for Naive Bayes model using test dataset\n",
    "y_prednb = Classifiernb.predict(x_test)\n",
    "accuracy_score(y_test, y_prednb)\n",
    "\n",
    "#Prediction and Accuracy for Naive Bayes model using training dataset\n",
    "y_prednbt = Classifiernb.predict(x_train)\n",
    "accuracy_score(y_train, y_prednbt)\n",
    "\n",
    "#Evaluation metrics for Naive Bayes model\n",
    "precision, recall, fscore, support = score(y_test, y_prednb,average = 'macro')\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "#Confusion matrix for Naive Bayes model\n",
    "cmnb = confusion_matrix(y_test, y_prednb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8872053872053873\n",
      "recall: 0.8737373737373737\n",
      "fscore: 0.8609427609427609\n",
      "support: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "RANDOM FOREST MODEL\n",
    "\"\"\"\n",
    "#Implementing Random Forest model\n",
    "Classifierrf = RandomForestClassifier()\n",
    "Classifierrf.fit(x_train, y_train)\n",
    "\n",
    "#Prediction and Accuracy for Random Forest model using test dataset\n",
    "y_predrf = Classifierrf.predict(x_test)\n",
    "accuracy_score(y_test, y_predrf)\n",
    "\n",
    "#Prediction and Accuracy for Random Forest model using training dataset\n",
    "y_predrft = Classifierrf.predict(x_train)\n",
    "accuracy_score(y_train, y_predrft)\n",
    "\n",
    "#Evaluation metrics for Random Forest model\n",
    "precision, recall, fscore, support = score(y_test, y_predrf,average = 'macro')\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "#Confusion matrix for Random Forest model\n",
    "cmdt = confusion_matrix(y_test, y_predrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9410774410774412\n",
      "recall: 0.9393939393939394\n",
      "fscore: 0.9292929292929294\n",
      "support: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82828283 0.87542088 0.88888889]\n",
      "0.8641975308641975\n",
      "0.025983921218384328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ENSEMBLE APPROACH USING VOTING CLASSIFIER\n",
    "\"\"\"\n",
    "#Implementing Ensemble model using Voting classifier\n",
    "ensemble = VotingClassifier(estimators=[('rf',Classifierrf),('dt',Classifierdt),('lr', Classifierlr), ('svm', Classifiersvm), ('gnb', Classifiernb)], voting='hard')\n",
    "ensemble = ensemble.fit(x_train, y_train)\n",
    "\n",
    "#Prediction and Accuracy for Ensemble model using test dataset\n",
    "y_predensemble = ensemble.predict(x_test)\n",
    "accuracy_score(y_test, y_predensemble)\n",
    "\n",
    "#Prediction and Accuracy for Ensemble model using training dataset\n",
    "y_predensemblet = ensemble.predict(x_train)\n",
    "accuracy_score(y_train, y_predensemblet)\n",
    "\n",
    "#Evaluation metrics for Ensemble model\n",
    "precision, recall, fscore, support = score(y_test, y_predensemble,average = 'macro')\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "#Confusion matrix for Ensemble model\n",
    "cm_en = confusion_matrix(y_test, y_predensemble)\n",
    "\n",
    "#Applying K fold for validation\n",
    "folds = cross_val_score(ensemble, x_train, y_train, cv=3)\n",
    "print(folds)\n",
    "print (folds.mean())\n",
    "\n",
    "print (folds.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "Accuracy: 58.0808%\n",
      "precision: 0.8872053872053873\n",
      "recall: 0.8737373737373737\n",
      "fscore: 0.8609427609427609\n",
      "support: None\n",
      "GaussianNB(priors=None)\n",
      "Accuracy: 57.0707%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Ajay\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8872053872053873\n",
      "recall: 0.8737373737373737\n",
      "fscore: 0.8609427609427609\n",
      "support: None\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001)\n",
      "Accuracy: 97.9798%\n",
      "precision: 0.8872053872053873\n",
      "recall: 0.8737373737373737\n",
      "fscore: 0.8609427609427609\n",
      "support: None\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "Accuracy: 4.0404%\n",
      "precision: 0.8872053872053873\n",
      "recall: 0.8737373737373737\n",
      "fscore: 0.8609427609427609\n",
      "support: None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = [\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for i in classifier:\n",
    "    \n",
    "    print (i)\n",
    "    i=i.fit(x_train,y_train)\n",
    "    train_predictions= i.predict(X_test)\n",
    "    ac=accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(ac))\n",
    "    \n",
    "    y_pred = i.predict(x_test)\n",
    "    accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    y_predlet = i.predict(x_train)\n",
    "    accuracy_score(y_train, y_predlet)\n",
    "    \n",
    "    \n",
    "    precision, recall, fscore, support = score(y_test, y_predrf,average = 'macro')\n",
    "    print('precision: {}'.format(precision))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('fscore: {}'.format(fscore))\n",
    "    print('support: {}'.format(support))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-233f84784909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_be\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m595\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_be\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m34\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msm_OLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_be\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msm_OLS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_be\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m34\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5164\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5165\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5166\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "x_be = np.append(arr=np.ones((1584,1)).astype(int), values=x_be ,axis=1)\n",
    "X_opt = x_be[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,2,3,4,5,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,2,3,4,5,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,2,3,4,5,6,8,9,10,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,2,3,4,5,6,8,9,10,12,13,14,15,16,18,19,20,21,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,2,3,4,5,6,8,9,10,12,13,14,15,16,19,20,21,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,2,3,4,5,6,8,10,12,13,14,15,16,19,20,21,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,3,4,5,6,8,10,12,13,14,15,16,19,20,21,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,3,4,6,8,10,12,13,14,15,16,19,20,21,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,3,4,6,8,10,12,13,14,15,16,19,20,21,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,3,4,6,8,10,12,13,14,15,16,19,20,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n",
    "X_opt = x_be[:, [0,1,3,4,6,8,10,12,13,14,15,19,20,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "sm_OLS = sm.OLS(endog = y_be, exog = X_opt).fit()\n",
    "sm_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
